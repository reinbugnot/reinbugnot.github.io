<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Forecasting using K-means Fuzzy Hybrid Model (WIP) | Rein Bugnot</title>
<meta name="keywords" content="fuzzy inference systems, kmeans, time series forecasting, data science">
<meta name="description" content="This project explores the use of a Hybrid model involving Fuzzy Inference Systems and K-Means clustering to perform time series forecasting.">
<meta name="author" content="Reinelle Jan Bugnot">
<link rel="canonical" href="https://reinbugnot.github.io/projects/paper1/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.ba1d931b8d3f8d2a69e875b94ec1b6a0ac7dff69e1208957e39c19b9b7fc8d45.css" integrity="sha256-uh2TG40/jSpp6HW5TsG2oKx9/2nhIIlX45wZubf8jUU=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://reinbugnot.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://reinbugnot.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://reinbugnot.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://reinbugnot.github.io/apple-touch-icon.png">

<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://reinbugnot.github.io/projects/paper1/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Forecasting using K-means Fuzzy Hybrid Model (WIP)" />
<meta property="og:description" content="This project explores the use of a Hybrid model involving Fuzzy Inference Systems and K-Means clustering to perform time series forecasting." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://reinbugnot.github.io/projects/paper1/" />
<meta property="og:image" content="https://reinbugnot.github.io/cover.png" /><meta property="article:section" content="projects" />
<meta property="article:published_time" content="2024-06-12T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-06-12T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://reinbugnot.github.io/cover.png" />
<meta name="twitter:title" content="Forecasting using K-means Fuzzy Hybrid Model (WIP)"/>
<meta name="twitter:description" content="This project explores the use of a Hybrid model involving Fuzzy Inference Systems and K-Means clustering to perform time series forecasting."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Projects",
      "item": "https://reinbugnot.github.io/projects/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Forecasting using K-means Fuzzy Hybrid Model (WIP)",
      "item": "https://reinbugnot.github.io/projects/paper1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Forecasting using K-means Fuzzy Hybrid Model (WIP)",
  "name": "Forecasting using K-means Fuzzy Hybrid Model (WIP)",
  "description": "This project explores the use of a Hybrid model involving Fuzzy Inference Systems and K-Means clustering to perform time series forecasting.",
  "keywords": [
    "fuzzy inference systems", "kmeans", "time series forecasting", "data science"
  ],
  "articleBody": " Download Slides\rCode and Data\rK-Means Fuzzy Time Series Forecasting (KM-FTS) The K-Means Fuzzy hybrid model consists of two (quite obvious) parts: (1) a K-Means clustering algorithm that identifies the positions of the centroids of the data distribution along the vertical axis and (2) a Fuzzy Time Series Forecasting model that utilizes a Fuzzy Inference Engine from dynamically generated triangular membership functions based on the positions of the centroids generated by the clustering algorithm.\nThis implementation is largely derived from the C-Means Fuzzy Time Series Forecasting hybrid model introduced by Alyousifi, et. al. in their paper “A new hybrid fuzzy time series model with an application to predict PM10 concentration\r”. C-Means Fuzzy or Fuzzy C-means is a clustering strategy that extends the traditional K-Means algorithm to accommodate fuzzy membership values. Unlike K-Means, where each data point belongs to only one cluster with a membership degree of 1, Fuzzy C-Means allows data points to belong to multiple clusters simultaneously with varying degrees of membership [8].\nFollowing the work of Alyousifi, et. al., however, I noticed that although the hybrid model primarily deals with fuzzy systems, the purpose that the clustering algorithm fulfills in the hybrid architecture (namely, finding centroid positions) does not require a fuzzy implementation. That is, regardless of whether each data point belongs to one or more cluster (and by extension, the corresponding centroid) the calculation of the centroid positions remains largely the same. Hence, in order to simplify the process, a standard K-Means clustering algorithm should suffice in identifying centroid positions that will later be used for dynamic partitioning. Shown below is a high-level overview of the model architecture implemented in the study.\nC-Means Fuzzy Time Series Model Flowchart (Alyousifi, et. al. Implementation) (left) and My Implementation (right) Unlike most other traditional forecasting models, FTS-based models such as the hybrid model proposed by the reference study primarily models the non-stationary form of the input time-series data (shown by the lack of differencing step in Fig. 3). That means the model training itself accounts for the trend and seasonalities embedded within the series. While these kinds of models are definitely capable of producing forecasts with high performance and reliability, one known drawback of not using stationary data is that it limits the forecasting range of the model to only within the “Universe of discourse\r” to which the model was trained on.\nData The dataset that I used in this project is the CapitaLand Ascendas Real Estate Investment Trust\r(REIT) (A17U.SI) because the timeseries features a wide data range for training and testing (more than 15-years span with daily resolution), relatively stable trend, and noticeable seasonal artifacts. To load the dataset, the .csv file was downloaded directly from Yahoo! Finance, and imported using Pandas.\nThe dataset features 6 value columns: Open, High, Low, Close, Adj Close and Volume. For this timeseries forecasting project, we are only concerned about the closing price of the trust. Using pandas, we can isolate this target column, and set the Date column as the index of the series. Converting the index into the standard DateTime format of Pandas, we see below that several NaN values appear.\n# Isolate Target Columns df = data.loc[:, ['Date', 'Close']] df.set_index('Date', inplace=True) # Set to date-time index df.index = pd.to_datetime(df.index) df = df.asfreq('D') df These NaN values (which stands for “not-a-number”) refers to non-numerical entries, which in this case, specifically identifies ‘gaps’ or empty entries in our series. Inspecting this further, we can easily identify the pattern and conclude that these gaps correspond to weekends and holidays. This is because the market is closed during weekends and holidays (situational). There are many ways to deal with gaps in our time series. One of the simplest (and effective) way is to perform a forward fill. This process basically fills in the gaps / missing entries with the value of the last observed entry. In the case of weekends, the forward fill function will use the Friday’s closing date as a proxy value for the ‘closing date of weekend days’.\n# Default option: use last observed data point df.fillna(method='ffill', inplace=True) We can then plot the entire time series data as shown in Fig. 1.\nFig. 1. CapitaLand Ascendas REIT Trust closing price data used in this forecasting project Most time series forecasting methods utilize the stationary form of the training dataset. A stationary time series is one whose statistical properties, such as mean, variance, and autocorrelation, do not change over time. In other words, the data points in a stationary time series are not dependent on time, and the series has a stable, constant behavior. Stationarity is an important concept in time series analysis because many time series models and statistical methods assume or work better with stationary data. Non-stationary time series can exhibit trends, seasonality, or other patterns that can make it challenging to analyze and model the underlying processes.\nIn order to derive the first order stationary form of a time series data, we need to calculate the difference between succeeding entries. We can easily do this using the .diff() function of a Pandas Dataframe, as shown in Fig. 2.\n#Convert df.diff().plot(title='Fig. 2. First Order Differencing', ylabel='Trust Value',figsize=(15,5), grid=True, color='purple') plt.show() However, the forecasting strategy implemented in this project, does not require the use of stationary data to perform excellently (although it does introduce notable limitations), as I’ll be demonstrating and discussing in the later sections of this project.\nFig. 2. Stationary Form of the CapitaLand Ascendas REIT Trust closing price data\nGenerate Fuzzy Membership Functions We begin by defining the model parameters–in this case, just one: n_partitions which also refers to the number of centroids that we expect the K-Means algorithm to generate.\n## MODEL PARAMETERS n_partitions = 50 # OR the 'k' in our k-means algorithm ## INPUT SERIES PARAMETERS # TEST SIZE n_days = 365 # TRAIN-TEST SPLIT (Train on first 14 years, test on last 1 year) train = df.values.reshape(-1,)[:-n_days * 1] test = df.values.reshape(-1,)[-n_days * 1:] Afterwards, the code below are simple helper functions for (1) implementing k-means clustering to find the centroid positions, and for (2) generating the set of fuzzy membership functions.\n# This allows us to package our membership functions into objects rather than storing the values directly in memory class fuzzymf(object): def __init__(self, Type, Parameters): self.Type = Type self.Parameters = Parameters def __repr__(self): return 'fismf, '\\ ' Type: %s, '\\ ' Parameters: %s\\n'\\ % (self.Type,self.Parameters) def get_centroids(x, method, PAD_RATIO = 0.05, n_partitions=None): \"\"\" Get the centroid values for the FTS model based on the selected method. args: x - time series data method - the method used to generate centroids: 'grid': generate evenly spaces centroids across the range of values 'kmeans': perform kmeans clustering algorithm to dynamically identify the best centroid positions based on data distribution PAD_RATIO - extend the left half of the left most membership function, and right half of the rightmost membership function by this amount n_partitions - number of partitions / number of centroids out: centroids - list of centroids (min_val, max_val) - minimum and maximum value of the entire rangne \"\"\" assert method in ['kmeans', 'grid'] val_range = max(x) - min(x) min_val = min(x) - (val_range * PAD_RATIO) max_val = max(x) + (val_range * PAD_RATIO) #pad_min, pad_max = (min(x) - partition_len * max(x), max(x) * (1 + partition_len)) # UNIFORMLY DISTRIBUTED CENTROIDS if method == 'grid': assert n_partitions != None, 'Please specify n_partitions' centroids = np.linspace(min_val, max_val, n_partitions+1, endpoint = False) centroids = centroids[1:] # KMEANS CENTROIDS elif method == 'kmeans': assert n_partitions != None, 'Please specify n_partitions' _, centroids = kmeans1d.cluster(x, n_partitions) else: print('Invalid method') return centroids, (min_val, max_val) def span_learnmf(x, method, n_partitions = None): \"\"\" Generate a set of fuzzy membership function objects (dict). args: x - time series data method - the method used to generate centroids (passed to get_centroids function): 'grid': generate evenly spaces centroids across the range of values 'kmeans': perform kmeans clustering algorithm to dynamically identify the best centroid positions based on data distribution n_partitions - number of partitions / number of centroids (passed to get_centroids function). out: mf - set \"\"\" centroids, (min_val, max_val) = get_centroids(x, method = method, n_partitions=n_partitions) mf={} for idx, centroid in enumerate(centroids): if idx == 0: mf[idx] = fuzzymf(Type = 'trimf', Parameters = [min_val, centroid, centroids[idx+1]]) elif idx == len(centroids) - 1: mf[idx] = fuzzymf(Type = 'trimf', Parameters = [centroids[idx-1], centroid, max_val]) else: mf[idx] = fuzzymf(Type = 'trimf', Parameters = [centroids[idx-1], centroid, centroids[idx+1]]) return mf, (min_val, max_val), centroids Using the fuzzymf class, we can then generate a set of N triangular membership functions where N = n_partitions [3]. Each triangular membership function requires 3 positional parameters [a,b,c] that defines the position of the left triangle leg, the triangle apex, and the right triangle leg, respectively. In this implementation, the values of a, b, and c are generally defined as follows: a - centroid value of the previous membership function b - centroid value of the current membership function c - centroid value of the next membership function For the membership functions in the extremities of the set (i.e., the leftmost and rightmost membership functions), the a and c value is defined by a padding ratio parameter PAD_RATIO applied to the min and max values of the universe of discourse U, respectively.\nThese centroid values are calculated using a 1-dimensional K-Means clustering algorithm that clusters the datapoints based on their distribution (histogram), the output of which is illustrated in Fig. 3.\n# Generate Membership Functions using K-Means fuzzy_set, (min_val, max_val), centroids = span_learnmf(train, 'kmeans', n_partitions=n_partitions) fig, ax = plt.subplots(nrows=1, ncols=1, figsize=[15,3]) for c in centroids: ax.axvline(c, color='r',linestyle='--') ax.hist(train, bins=100) plt.xlabel('Trust Value') plt.ylabel('Count') plt.show() Fig. 3. Datapoint Distribution and Calculated Centroid Positions\nUsing the calculated centroids, we can then generate a set of membership functions, a snippet of which is illustrated in Fig. 4.\nFrom the figure shown, we can get an idea of how the K-Means clustering algorithm influences the distribution of membership centroid values. We can see how the membership values somehow cluster tightly in areas where the data distribution is high, and loosely in areas where the data distribution is low. This is the main strength of using a clustering algorithm like (1-dimensional) K-means is that it allows us to assign more centroids in areas where the concentration of data points is high. This allows us to increase the granularity of our inferencing system in areas where it is most needed.\n# Plot Membership Functions fig, ax = plt.subplots(nrows=1, ncols=1, figsize=[15,3]) for i in range(len(fuzzy_set)): x = np.linspace(min_val, max_val, (n_partitions+1)*20, endpoint = False) ax.plot(x, evalmf(fuzzy_set[i], x), label='Winning Vector 1') ax.set_xticks(x[::10]) ax.set_xlim([1,2]) ax.set_ylim([0,1.01]) ax.tick_params(axis='x', rotation=90, labelsize=6) plt.figure(figsize=(15,1.25)) plt.hist(train, density=True, bins=100) plt.xlim([1,2]) plt.ylim([0,1.01]) plt.show() plt.tight_layout() Fig. 4. Triangle Membership Functions from K-Means Centroids \\n (Zoomed in to the range of 1 to 2)\nWe can plot all N membership functions on top of the original time series data to visualize how the membership functions interact with the original data that it is derived from, as shown in Fig. 5.\n# Plot Generated Membership Functions x = np.linspace(min_val, max_val, (n_partitions+1)*20, endpoint = False) fig, ax = plt.subplots(figsize=(15,5)) ax.plot(df.index, df.values) ax.set_ylabel('Trust Value') ax.set_xlabel('Date') ## Uncomment this if we want to zoom in on a particular y value range # ax.set_ylim([2,2.5]) ax2 = ax.twiny() for i in range(len(fuzzy_set)): ax2.plot(evalmf(fuzzy_set[i], x), x, label='Winning Vector 1') ax2.set_xlim([0,10]) ax2.set_xticks([]) plt.show() Fig. 5. A17U.SI Time Series with the Kmeans-generated fuzzy membership functions\nTO BE CONTINUED Citation [1] Y. Alyousifi, M. Othman and A. A. Almohammedi, “A Novel Stochastic Fuzzy Time Series Forecasting Model Based on a New Partition Method,” in IEEE Access, 2021 [2] Alyousifi, Yousif \u0026 Mahmod, Othman \u0026 Husin, Abdullah \u0026 Rathnayake, Upaka. A new hybrid fuzzy time series model with an application to predict PM10 concentration. Ecotoxicology and Environmental SafetY, 2021 [3] A. Kai Keng, Fuzzy Memberships, AI6124 Assignment 3, Nanyang Technological University, 2023. [4] A. Kai Keng, POPFNN, AI6124 Assignment 4, Nanyang Technological University, 2023. [5] W. Di, Week 5: Clustering, AI6124 Lecture Slides, Nanyang Technological University, 2023. [6] W. Di, Week 4 - Part 1: Fuzzy Set, Fuzzy Logic, Fuzzy Rule Based System, AI6124 Lecture Slides, Nanyang Technological University, 2023. [7] J. B. Maverick, “How is the exponential moving average (EMA) formula calculated?,” Investopedia, https://www.investopedia.com/ask/answers/122314/what-exponential-moving-average-ema-formula-and-how-ema-calculated.asp\r(accessed Nov. 22, 2023). [8] A. Gupta, “Fuzzy C-means clustering (FCM) algorithm in Machine Learning,” Medium, https://medium.com/geekculture/fuzzy-c-means-clustering-fcm-algorithm-in-machine-learning-c2e51e586fff\r(accessed Nov. 22, 2023). ",
  "wordCount" : "2089",
  "inLanguage": "en",
  "image":"https://reinbugnot.github.io/cover.png","datePublished": "2024-06-12T00:00:00Z",
  "dateModified": "2024-06-12T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Reinelle Jan Bugnot"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://reinbugnot.github.io/projects/paper1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Rein Bugnot",
    "logo": {
      "@type": "ImageObject",
      "url": "https://reinbugnot.github.io/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://reinbugnot.github.io/" accesskey="h" title="Rein Bugnot">
             
                <img src="https://reinbugnot.github.io/favicon.ico" alt="" aria-label="logo"
                    height="18"
                    width="18">Rein Bugnot</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://reinbugnot.github.io/cv/" title="CV">
                    <span>CV</span>
                </a>
            </li>
            <li>
                <a href="https://reinbugnot.github.io/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Forecasting using K-means Fuzzy Hybrid Model (WIP)
    </h1>
    <div class="post-meta"><span title='2024-06-12 00:00:00 +0000 UTC'>June 2024</span>&nbsp;&middot;&nbsp;Reinelle Jan Bugnot&nbsp;&middot;&nbsp;<a href="https://github.com/reinbugnot/kmeans-fuzzy-ts-forecast/tree/main" rel="noopener noreferrer" target="_blank">AI6124 Neuro Evolution and Fuzzy Intelligence</a>

</div>
  </header> 
  <div class="post-content"><hr>
<h5 id="download">Download</h5>
<ul>
<li><a href="slides.pdf">Slides</a>
</li>
<li><a href="https://github.com/reinbugnot/kmeans-fuzzy-ts-forecast/tree/main" target="_blank">Code and Data</a>
</li>
</ul>
<hr>
<p><img loading="lazy" src="cover.png" alt=""  />
</p>
<hr>
<h2 id="k-means-fuzzy-time-series-forecasting-km-fts">K-Means Fuzzy Time Series Forecasting (KM-FTS)</h2>
<p>The K-Means Fuzzy hybrid model consists of two (quite obvious) parts: (1) a <strong>K-Means clustering</strong> algorithm that identifies the positions of the centroids of the data distribution along the vertical axis and (2) a <strong>Fuzzy</strong> Time Series Forecasting model that utilizes a Fuzzy Inference Engine from dynamically generated triangular membership functions based on the positions of the centroids generated by the clustering algorithm.</p>
<p>This implementation is largely derived from the C-Means Fuzzy Time Series Forecasting hybrid model introduced by Alyousifi, et. al. in their paper &ldquo;<a href="https://www.sciencedirect.com/science/article/pii/S0147651321009878" target="_blank">A new hybrid fuzzy time series model with an application to predict PM10 concentration</a>
&rdquo;. C-Means Fuzzy or Fuzzy C-means is a clustering strategy that extends the traditional K-Means algorithm to accommodate fuzzy membership values. Unlike K-Means, where each data point belongs to only one cluster with a membership degree of 1, Fuzzy C-Means allows data points to belong to multiple clusters simultaneously with varying degrees of membership [8].</p>
<p>Following the work of Alyousifi, et. al., however, I noticed that although the hybrid model primarily deals with fuzzy systems, the purpose that the clustering algorithm fulfills in the hybrid architecture (namely, finding centroid positions) does not require a fuzzy implementation. That is, regardless of whether each data point belongs to one or more cluster (and by extension, the corresponding centroid) the calculation of the centroid positions remains largely the same. Hence, in order to simplify the process, a standard K-Means clustering algorithm should suffice in identifying centroid positions that will later be used for dynamic partitioning. Shown below is a high-level overview of the model architecture implemented in the study.</p>
<p><img loading="lazy" src="flowcharts.png" alt=""  />
</p>
<p><em><p style="text-align:center; font-size: 16px"> C-Means Fuzzy Time Series Model Flowchart (Alyousifi, et. al. Implementation) (left) and My Implementation (right) </p></em></p>
<p>Unlike most other traditional forecasting models, FTS-based models such as the hybrid model proposed by the reference study primarily models the non-stationary form of the input time-series data (shown by the lack of differencing step in Fig. 3). That means the model training itself accounts for the trend and seasonalities embedded within the series. While these kinds of models are definitely capable of producing forecasts with high performance and reliability, one known drawback of not using stationary data is that it limits the forecasting range of the model to only within the &ldquo;<a href="https://www.researchgate.net/figure/Universe-of-discourse-error-fuzzy-sets_fig1_221785971" target="_blank">Universe of discourse</a>
&rdquo; to which the model was trained on.</p>
<h3 id="data">Data</h3>
<p>The dataset that I used in this project is the <a href="https://finance.yahoo.com/quote/A17U.SI/?p=A17U.SI&amp;.tsrc=fin-srch" target="_blank">CapitaLand Ascendas Real Estate Investment Trust</a>
 (REIT) (A17U.SI) because the timeseries features a wide data range for training and testing (more than 15-years span with daily resolution), relatively stable trend, and noticeable seasonal artifacts. To load the dataset, the .csv file was downloaded directly from Yahoo! Finance, and imported using Pandas.</p>
<p>The dataset features 6 value columns: Open, High, Low, Close, Adj Close and Volume. For this timeseries forecasting project, we are only concerned about the closing price of the trust. Using pandas, we can isolate this target column, and set the Date column as the index of the series. Converting the index into the standard DateTime format of Pandas, we see below that several NaN values appear.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span><span style="color:#aaa;font-style:italic"># Isolate Target Columns</span>
</span></span><span style="display:flex;"><span>df = data.loc[:, [<span style="color:#a50">&#39;Date&#39;</span>, <span style="color:#a50">&#39;Close&#39;</span>]]
</span></span><span style="display:flex;"><span>df.set_index(<span style="color:#a50">&#39;Date&#39;</span>, inplace=<span style="color:#00a">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic"># Set to date-time index</span>
</span></span><span style="display:flex;"><span>df.index = pd.to_datetime(df.index)
</span></span><span style="display:flex;"><span>df = df.asfreq(<span style="color:#a50">&#39;D&#39;</span>)
</span></span><span style="display:flex;"><span>df
</span></span></code></pre></div><img src="closing.png" width="175" />
<p>These NaN values (which stands for &ldquo;not-a-number&rdquo;) refers to non-numerical entries, which in this case, specifically identifies &lsquo;gaps&rsquo; or empty entries in our series. Inspecting this further, we can easily identify the pattern and conclude that these gaps correspond to weekends and holidays. This is because the market is closed during weekends and holidays (situational). There are many ways to deal with gaps in our time series. One of the simplest (and effective) way is to perform a <em>forward fill</em>. This process basically fills in the gaps / missing entries with the value of the last observed entry. In the case of weekends, the forward fill function will use the Friday&rsquo;s closing date as a proxy value for the &lsquo;closing date of weekend days&rsquo;.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span><span style="color:#aaa;font-style:italic"># Default option: use last observed data point</span>
</span></span><span style="display:flex;"><span>df.fillna(method=<span style="color:#a50">&#39;ffill&#39;</span>, inplace=<span style="color:#00a">True</span>)
</span></span></code></pre></div><p>We can then plot the entire time series data as shown in Fig. 1.</p>
<p><img loading="lazy" src="data.png" alt=""  />
</p>
<p><em><p style="text-align:center; font-size: 16px"> Fig. 1. CapitaLand Ascendas REIT Trust closing price data used in this forecasting project </p></em></p>
<p>Most time series forecasting methods utilize the stationary form of the training dataset. A stationary time series is one whose statistical properties, such as mean, variance, and autocorrelation, do not change over time. In other words, the data points in a stationary time series are not dependent on time, and the series has a stable, constant behavior. Stationarity is an important concept in time series analysis because many time series models and statistical methods assume or work better with stationary data. Non-stationary time series can exhibit trends, seasonality, or other patterns that can make it challenging to analyze and model the underlying processes.</p>
<p>In order to derive the first order stationary form of a time series data, we need to calculate the difference between succeeding entries. We can easily do this using the .diff() function of a Pandas Dataframe, as shown in Fig. 2.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span><span style="color:#aaa;font-style:italic">#Convert </span>
</span></span><span style="display:flex;"><span>df.diff().plot(title=<span style="color:#a50">&#39;Fig. 2. First Order Differencing&#39;</span>, ylabel=<span style="color:#a50">&#39;Trust Value&#39;</span>,figsize=(<span style="color:#099">15</span>,<span style="color:#099">5</span>), grid=<span style="color:#00a">True</span>, color=<span style="color:#a50">&#39;purple&#39;</span>)
</span></span><span style="display:flex;"><span>plt.show()
</span></span></code></pre></div><p>However, the forecasting strategy implemented in this project, does not require the use of stationary data to perform excellently (although it does introduce notable limitations), as I&rsquo;ll be demonstrating and discussing in the later sections of this project.</p>
<p><img loading="lazy" src="stationary.png" alt=""  />

<em><p style="text-align:center; font-size: 16px"> Fig. 2. Stationary Form of the CapitaLand Ascendas REIT Trust closing price data</p></em></p>
<hr>
<h3 id="generate-fuzzy-membership-functions">Generate Fuzzy Membership Functions</h3>
<p>We begin by defining the model parameters&ndash;in this case, just one: n_partitions which also refers to the number of centroids that we expect the K-Means algorithm to generate.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span><span style="color:#aaa;font-style:italic">## MODEL PARAMETERS</span>
</span></span><span style="display:flex;"><span>n_partitions = <span style="color:#099">50</span> <span style="color:#aaa;font-style:italic"># OR the &#39;k&#39; in our k-means algorithm</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic">## INPUT SERIES PARAMETERS</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic"># TEST SIZE</span>
</span></span><span style="display:flex;"><span>n_days = <span style="color:#099">365</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic"># TRAIN-TEST SPLIT (Train on first 14 years, test on last 1 year)</span>
</span></span><span style="display:flex;"><span>train = df.values.reshape(-<span style="color:#099">1</span>,)[:-n_days * <span style="color:#099">1</span>]
</span></span><span style="display:flex;"><span>test = df.values.reshape(-<span style="color:#099">1</span>,)[-n_days * <span style="color:#099">1</span>:]
</span></span></code></pre></div><p>Afterwards, the code below are simple helper functions for (1) implementing k-means clustering to find the centroid positions, and for (2) generating the set of fuzzy membership functions.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span><span style="color:#aaa;font-style:italic"># This allows us to package our membership functions into objects rather than storing the values directly in memory</span>
</span></span><span style="display:flex;"><span><span style="color:#00a">class</span> <span style="color:#0a0;text-decoration:underline">fuzzymf</span>(<span style="color:#0aa">object</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#00a">def</span> __init__(self, Type, Parameters):
</span></span><span style="display:flex;"><span>        self.Type = Type
</span></span><span style="display:flex;"><span>        self.Parameters = Parameters
</span></span><span style="display:flex;"><span>    <span style="color:#00a">def</span> __repr__(self):
</span></span><span style="display:flex;"><span>            <span style="color:#00a">return</span> <span style="color:#a50">&#39;fismf, &#39;</span>\
</span></span><span style="display:flex;"><span>                <span style="color:#a50">&#39; Type: </span><span style="color:#a50">%s</span><span style="color:#a50">, &#39;</span>\
</span></span><span style="display:flex;"><span>                <span style="color:#a50">&#39; Parameters: </span><span style="color:#a50">%s</span><span style="color:#a50">\n</span><span style="color:#a50">&#39;</span>\
</span></span><span style="display:flex;"><span>                % (self.Type,self.Parameters)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span><span style="color:#00a">def</span> <span style="color:#0a0">get_centroids</span>(x, method, PAD_RATIO = <span style="color:#099">0.05</span>, n_partitions=<span style="color:#00a">None</span>):
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#a50">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#a50">    Get the centroid values for the FTS model based on the selected method.
</span></span></span><span style="display:flex;"><span><span style="color:#a50">    
</span></span></span><span style="display:flex;"><span><span style="color:#a50">    args:
</span></span></span><span style="display:flex;"><span><span style="color:#a50">        x - time series data
</span></span></span><span style="display:flex;"><span><span style="color:#a50">        method - the method used to generate centroids:
</span></span></span><span style="display:flex;"><span><span style="color:#a50">            &#39;grid&#39;: generate evenly spaces centroids across the range of values
</span></span></span><span style="display:flex;"><span><span style="color:#a50">            &#39;kmeans&#39;: perform kmeans clustering algorithm to dynamically identify the best centroid positions based on data distribution
</span></span></span><span style="display:flex;"><span><span style="color:#a50">        PAD_RATIO - extend the left half of the left most membership function, and right half of the rightmost membership function by this amount
</span></span></span><span style="display:flex;"><span><span style="color:#a50">        n_partitions - number of partitions / number of centroids
</span></span></span><span style="display:flex;"><span><span style="color:#a50">    
</span></span></span><span style="display:flex;"><span><span style="color:#a50">    out:
</span></span></span><span style="display:flex;"><span><span style="color:#a50">        centroids - list of centroids
</span></span></span><span style="display:flex;"><span><span style="color:#a50">        (min_val, max_val) - minimum and maximum value of the entire rangne 
</span></span></span><span style="display:flex;"><span><span style="color:#a50">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#00a">assert</span> method <span style="color:#00a">in</span> [<span style="color:#a50">&#39;kmeans&#39;</span>, <span style="color:#a50">&#39;grid&#39;</span>]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    val_range = <span style="color:#0aa">max</span>(x) - <span style="color:#0aa">min</span>(x)
</span></span><span style="display:flex;"><span>    min_val = <span style="color:#0aa">min</span>(x) - (val_range * PAD_RATIO)
</span></span><span style="display:flex;"><span>    max_val = <span style="color:#0aa">max</span>(x) + (val_range * PAD_RATIO)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#aaa;font-style:italic">#pad_min, pad_max = (min(x) - partition_len * max(x), max(x) * (1 + partition_len))</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#aaa;font-style:italic"># UNIFORMLY DISTRIBUTED CENTROIDS</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a">if</span> method == <span style="color:#a50">&#39;grid&#39;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#00a">assert</span> n_partitions != <span style="color:#00a">None</span>, <span style="color:#a50">&#39;Please specify n_partitions&#39;</span>
</span></span><span style="display:flex;"><span>        centroids = np.linspace(min_val, max_val, n_partitions+<span style="color:#099">1</span>, endpoint = <span style="color:#00a">False</span>)
</span></span><span style="display:flex;"><span>        centroids = centroids[<span style="color:#099">1</span>:]
</span></span><span style="display:flex;"><span>    <span style="color:#aaa;font-style:italic"># KMEANS CENTROIDS</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a">elif</span> method == <span style="color:#a50">&#39;kmeans&#39;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#00a">assert</span> n_partitions != <span style="color:#00a">None</span>, <span style="color:#a50">&#39;Please specify n_partitions&#39;</span>
</span></span><span style="display:flex;"><span>        _, centroids = kmeans1d.cluster(x, n_partitions)
</span></span><span style="display:flex;"><span>    <span style="color:#00a">else</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#0aa">print</span>(<span style="color:#a50">&#39;Invalid method&#39;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#00a">return</span> centroids, (min_val, max_val)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span><span style="color:#00a">def</span> <span style="color:#0a0">span_learnmf</span>(x, method, n_partitions = <span style="color:#00a">None</span>):
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#a50">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#a50">    Generate a set of fuzzy membership function objects (dict).
</span></span></span><span style="display:flex;"><span><span style="color:#a50">    
</span></span></span><span style="display:flex;"><span><span style="color:#a50">    args:
</span></span></span><span style="display:flex;"><span><span style="color:#a50">        x - time series data
</span></span></span><span style="display:flex;"><span><span style="color:#a50">        method - the method used to generate centroids (passed to get_centroids function):
</span></span></span><span style="display:flex;"><span><span style="color:#a50">            &#39;grid&#39;: generate evenly spaces centroids across the range of values
</span></span></span><span style="display:flex;"><span><span style="color:#a50">            &#39;kmeans&#39;: perform kmeans clustering algorithm to dynamically identify the best centroid positions based on data distribution
</span></span></span><span style="display:flex;"><span><span style="color:#a50">        n_partitions - number of partitions / number of centroids (passed to get_centroids function).
</span></span></span><span style="display:flex;"><span><span style="color:#a50">        
</span></span></span><span style="display:flex;"><span><span style="color:#a50">    out:
</span></span></span><span style="display:flex;"><span><span style="color:#a50">        mf - set 
</span></span></span><span style="display:flex;"><span><span style="color:#a50">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    centroids, (min_val, max_val) = get_centroids(x, method = method, n_partitions=n_partitions)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    mf={}
</span></span><span style="display:flex;"><span>    <span style="color:#00a">for</span> idx, centroid <span style="color:#00a">in</span> <span style="color:#0aa">enumerate</span>(centroids):
</span></span><span style="display:flex;"><span>        <span style="color:#00a">if</span> idx == <span style="color:#099">0</span>:
</span></span><span style="display:flex;"><span>            mf[idx] = fuzzymf(Type = <span style="color:#a50">&#39;trimf&#39;</span>, Parameters = [min_val, centroid, centroids[idx+<span style="color:#099">1</span>]])
</span></span><span style="display:flex;"><span>        <span style="color:#00a">elif</span> idx == <span style="color:#0aa">len</span>(centroids) - <span style="color:#099">1</span>:
</span></span><span style="display:flex;"><span>            mf[idx] = fuzzymf(Type = <span style="color:#a50">&#39;trimf&#39;</span>, Parameters = [centroids[idx-<span style="color:#099">1</span>], centroid, max_val])
</span></span><span style="display:flex;"><span>        <span style="color:#00a">else</span>:
</span></span><span style="display:flex;"><span>            mf[idx] = fuzzymf(Type = <span style="color:#a50">&#39;trimf&#39;</span>, Parameters = [centroids[idx-<span style="color:#099">1</span>], centroid, centroids[idx+<span style="color:#099">1</span>]])
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>    <span style="color:#00a">return</span> mf, (min_val, max_val), centroids
</span></span></code></pre></div><p>Using the fuzzymf class, we can then generate a set of N triangular membership functions where N = n_partitions [3]. Each triangular membership function requires 3 positional parameters <code>[a,b,c]</code> that defines the position of the left triangle leg, the triangle apex, and the right triangle leg, respectively. In this implementation, the values of a, b, and c are generally defined as follows: <br></p>
<p><em>a</em> - centroid value of the previous membership function <br>
<em>b</em> - centroid value of the current membership function <br>
<em>c</em> - centroid value of the next membership function <br></p>
<p>For the membership functions in the extremities of the set (i.e., the leftmost and rightmost membership functions), the <em>a</em> and <em>c</em> value is defined by a padding ratio parameter <code>PAD_RATIO</code> applied to the min and max values of the universe of discourse U, respectively.</p>
<p>These centroid values are calculated using a 1-dimensional K-Means clustering algorithm that clusters the datapoints based on their distribution (histogram), the output of which is illustrated in Fig. 3.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic"># Generate Membership Functions using K-Means</span>
</span></span><span style="display:flex;"><span>fuzzy_set, (min_val, max_val), centroids = span_learnmf(train, <span style="color:#a50">&#39;kmeans&#39;</span>, n_partitions=n_partitions)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig, ax = plt.subplots(nrows=<span style="color:#099">1</span>, ncols=<span style="color:#099">1</span>, figsize=[<span style="color:#099">15</span>,<span style="color:#099">3</span>])
</span></span><span style="display:flex;"><span><span style="color:#00a">for</span> c <span style="color:#00a">in</span> centroids:
</span></span><span style="display:flex;"><span>    ax.axvline(c, color=<span style="color:#a50">&#39;r&#39;</span>,linestyle=<span style="color:#a50">&#39;--&#39;</span>)
</span></span><span style="display:flex;"><span>ax.hist(train, bins=<span style="color:#099">100</span>)
</span></span><span style="display:flex;"><span>plt.xlabel(<span style="color:#a50">&#39;Trust Value&#39;</span>)
</span></span><span style="display:flex;"><span>plt.ylabel(<span style="color:#a50">&#39;Count&#39;</span>)
</span></span><span style="display:flex;"><span>plt.show()
</span></span></code></pre></div><p><img loading="lazy" src="fig3.png" alt=""  />

<em><p style="text-align:center; font-size: 16px"> Fig. 3. Datapoint Distribution and Calculated Centroid Positions</p></em></p>
<p>Using the calculated centroids, we can then generate a set of membership functions, a snippet of which is illustrated in Fig. 4.</p>
<p>From the figure shown, we can get an idea of how the K-Means clustering algorithm influences the distribution of membership centroid values. We can see how the membership values somehow cluster tightly in areas where the data distribution is high, and loosely in areas where the data distribution is low. This is the main strength of using a clustering algorithm like (1-dimensional) K-means is that it allows us to assign more centroids in areas where the concentration of data points is high. This allows us to increase the granularity of our inferencing system in areas where it is most needed.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span><span style="color:#aaa;font-style:italic"># Plot Membership Functions</span>
</span></span><span style="display:flex;"><span>fig, ax = plt.subplots(nrows=<span style="color:#099">1</span>, ncols=<span style="color:#099">1</span>, figsize=[<span style="color:#099">15</span>,<span style="color:#099">3</span>])
</span></span><span style="display:flex;"><span><span style="color:#00a">for</span> i <span style="color:#00a">in</span> <span style="color:#0aa">range</span>(<span style="color:#0aa">len</span>(fuzzy_set)):
</span></span><span style="display:flex;"><span>    x = np.linspace(min_val, max_val, (n_partitions+<span style="color:#099">1</span>)*<span style="color:#099">20</span>, endpoint = <span style="color:#00a">False</span>)
</span></span><span style="display:flex;"><span>    ax.plot(x, evalmf(fuzzy_set[i], x), label=<span style="color:#a50">&#39;Winning Vector 1&#39;</span>)
</span></span><span style="display:flex;"><span>    ax.set_xticks(x[::<span style="color:#099">10</span>])
</span></span><span style="display:flex;"><span>    ax.set_xlim([<span style="color:#099">1</span>,<span style="color:#099">2</span>])
</span></span><span style="display:flex;"><span>    ax.set_ylim([<span style="color:#099">0</span>,<span style="color:#099">1.01</span>])
</span></span><span style="display:flex;"><span>    ax.tick_params(axis=<span style="color:#a50">&#39;x&#39;</span>, rotation=<span style="color:#099">90</span>, labelsize=<span style="color:#099">6</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>plt.figure(figsize=(<span style="color:#099">15</span>,<span style="color:#099">1.25</span>))
</span></span><span style="display:flex;"><span>plt.hist(train, density=<span style="color:#00a">True</span>, bins=<span style="color:#099">100</span>)
</span></span><span style="display:flex;"><span>plt.xlim([<span style="color:#099">1</span>,<span style="color:#099">2</span>])
</span></span><span style="display:flex;"><span>plt.ylim([<span style="color:#099">0</span>,<span style="color:#099">1.01</span>])
</span></span><span style="display:flex;"><span>plt.show()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt.tight_layout()
</span></span></code></pre></div><p><img loading="lazy" src="fig4.png" alt=""  />

<em><p style="text-align:center; font-size: 16px"> Fig. 4. Triangle Membership Functions from K-Means Centroids \n (Zoomed in to the range of 1 to 2)</p></em></p>
<p>We can plot all N membership functions on top of the original time series data to visualize how the membership functions interact with the original data that it is derived from, as shown in Fig. 5.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span><span style="color:#aaa;font-style:italic"># Plot Generated Membership Functions</span>
</span></span><span style="display:flex;"><span>x = np.linspace(min_val, max_val, (n_partitions+<span style="color:#099">1</span>)*<span style="color:#099">20</span>, endpoint = <span style="color:#00a">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig, ax = plt.subplots(figsize=(<span style="color:#099">15</span>,<span style="color:#099">5</span>))
</span></span><span style="display:flex;"><span>ax.plot(df.index, df.values)
</span></span><span style="display:flex;"><span>ax.set_ylabel(<span style="color:#a50">&#39;Trust Value&#39;</span>)
</span></span><span style="display:flex;"><span>ax.set_xlabel(<span style="color:#a50">&#39;Date&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic">## Uncomment this if we want to zoom in on a particular y value range</span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic"># ax.set_ylim([2,2.5])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax2 = ax.twiny()
</span></span><span style="display:flex;"><span><span style="color:#00a">for</span> i <span style="color:#00a">in</span> <span style="color:#0aa">range</span>(<span style="color:#0aa">len</span>(fuzzy_set)):
</span></span><span style="display:flex;"><span>    ax2.plot(evalmf(fuzzy_set[i], x), x, label=<span style="color:#a50">&#39;Winning Vector 1&#39;</span>)
</span></span><span style="display:flex;"><span>    ax2.set_xlim([<span style="color:#099">0</span>,<span style="color:#099">10</span>])
</span></span><span style="display:flex;"><span>    ax2.set_xticks([])
</span></span><span style="display:flex;"><span>plt.show()
</span></span></code></pre></div><p><img loading="lazy" src="fig5.png" alt=""  />

<em><p style="text-align:center; font-size: 16px"> Fig. 5. A17U.SI Time Series with the Kmeans-generated fuzzy membership functions</p></em></p>
<p><strong><p style="text-align:center"> TO BE CONTINUED </p></strong></p>
<hr>
<h5 id="citation">Citation</h5>
<p>[1] Y. Alyousifi, M. Othman and A. A. Almohammedi, &ldquo;A Novel Stochastic Fuzzy Time Series Forecasting Model Based on a New Partition Method,&rdquo; in IEEE Access, 2021 <br>
[2] Alyousifi, Yousif &amp; Mahmod, Othman &amp; Husin, Abdullah &amp; Rathnayake, Upaka. A new hybrid fuzzy time series model with an application to predict PM10 concentration. Ecotoxicology and Environmental SafetY, 2021 <br>
[3] A. Kai Keng, Fuzzy Memberships, AI6124 Assignment 3, Nanyang Technological University, 2023. <br>
[4] A. Kai Keng, POPFNN, AI6124 Assignment 4, Nanyang Technological University, 2023. <br>
[5] W. Di, Week 5: Clustering, AI6124 Lecture Slides, Nanyang Technological University, 2023. <br>
[6] W. Di, Week 4 - Part 1: Fuzzy Set, Fuzzy Logic, Fuzzy Rule Based System, AI6124 Lecture Slides, Nanyang Technological University, 2023. <br>
[7] J. B. Maverick, “How is the exponential moving average (EMA) formula calculated?,” Investopedia, <a href="https://www.investopedia.com/ask/answers/122314/what-exponential-moving-average-ema-formula-and-how-ema-calculated.asp" target="_blank">https://www.investopedia.com/ask/answers/122314/what-exponential-moving-average-ema-formula-and-how-ema-calculated.asp</a>
 (accessed Nov. 22, 2023). [8] A. Gupta, “Fuzzy C-means clustering (FCM) algorithm in Machine Learning,” Medium, <a href="https://medium.com/geekculture/fuzzy-c-means-clustering-fcm-algorithm-in-machine-learning-c2e51e586fff" target="_blank">https://medium.com/geekculture/fuzzy-c-means-clustering-fcm-algorithm-in-machine-learning-c2e51e586fff</a>
 (accessed Nov. 22, 2023). <br></p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-BibTeX" data-lang="BibTeX"><span style="display:flex;"><span><span style="color:#aaa;font-style:italic">&lt;!-- @article{UV01,</span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic">author = {Detlev A. Unterholzer and Moritz-Maria von Igelfeld},</span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic">year = {2001},</span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic">title ={Unusual Uses For Olive Oil},</span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic">journal = {Journal of Oleic Science},</span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic">volume = {34),</span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic">number = {1},</span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic">pages = {449--489},</span>
</span></span><span style="display:flex;"><span><span style="color:#aaa;font-style:italic">url = {http://www.alexandermccallsmith.com/book/unusual-uses-for-olive-oil}} --&gt;</span>
</span></span></code></pre></div><hr>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://reinbugnot.github.io/tags/fuzzy-inference-systems/">Fuzzy Inference Systems</a></li>
      <li><a href="https://reinbugnot.github.io/tags/kmeans/">Kmeans</a></li>
      <li><a href="https://reinbugnot.github.io/tags/time-series-forecasting/">Time Series Forecasting</a></li>
      <li><a href="https://reinbugnot.github.io/tags/data-science/">Data Science</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    &copy; 2024 Rein Bugnot
    <span>
    &middot;  Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">a modified version</a>
         of 
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
